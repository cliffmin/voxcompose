# VoxCompose

**Smart transcript refinement with self-learning corrections and local LLM processing**

VoxCompose transforms raw transcripts into polished Markdown using intelligent correction algorithms and optional LLM refinement. It learns from your corrections and applies them automatically‚Äîno cloud services required.

### üèÜ Major Achievements in v1.0.0

| Metric | Improvement | Impact |
|--------|-------------|--------|
| **Processing Speed** | 92% faster | 1,800ms ‚Üí 142ms for short inputs |
| **Error Reduction** | 75% fewer errors | 20% ‚Üí 5% error rate |
| **LLM Usage** | 70% reduction | Smart threshold skips unnecessary calls |
| **Accuracy** | 100% on technical terms | Perfect correction of common patterns |

## ‚ú® Key Features

- **üß† Self-Learning Corrections**: Automatically fixes common transcription errors without LLM
- **‚ö° Smart Processing**: Uses corrections-only for inputs <21s, adds LLM for longer content
- **üîí Privacy-First**: 100% local processing with Ollama, no API keys needed
- **üìä 75% Error Reduction**: Proven accuracy improvements on technical content
- **üöÄ Fast**: 139ms average processing time for short inputs

## üìö Documentation

- **[üìà Performance Improvements](docs/performance.md)** - Detailed metrics showing 92% speed improvement
- **[üß† Self-Learning System](docs/self-learning.md)** - How the AI learns from your usage
- **[üèóÔ∏è Technical Architecture](docs/architecture.md)** - System design and implementation
- **[üçé VoxCore Integration](docs/voxcore-integration.md)** - Setup with VoxCore push-to-talk

## üìà Performance & Accuracy

### Self-Learning Corrections Impact

```
ACCURACY IMPROVEMENTS (Before ‚Üí After)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Word Concatenations:
  Before: 0%   |                    |
  After:  100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| +100%

Technical Terms:
  Before: 20%  |‚ñà‚ñà‚ñà‚ñà                |
  After:  100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| +80%

Overall Accuracy:
  Before: 80%  |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    |
  After:  95%  |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | +15%
```

### Smart Processing Strategy

| Input Duration | Strategy | Processing Time | Benefits |
|---|---|---|---|
| < 21 seconds | Corrections Only | 139ms | ‚ö° Fast, no LLM needed |
| ‚â• 21 seconds | Corrections + LLM | 2.6s | üéØ Full refinement |

### Automatic Corrections Examples

**Word Concatenations** ‚Üí Fixed automatically
- `pushto` ‚Üí `push to`
- `committhis` ‚Üí `commit this`
- `followup` ‚Üí `follow up`

**Technical Capitalizations** ‚Üí Applied instantly
- `github` ‚Üí `GitHub`
- `json` ‚Üí `JSON`
- `nodejs` ‚Üí `Node.js`
- `postgresql` ‚Üí `PostgreSQL`

## üöÄ Quick Start

```bash
# Install via Homebrew
brew tap cliffmin/tap
brew install voxcompose ollama

# Start Ollama and pull a model
ollama serve &
ollama pull llama3.1

# Test it
echo "i want to pushto github and committhis code" | voxcompose
# Output: "I want to push to GitHub and commit this code"
```

## üîß Configuration

### Key Options

| Option | Description | Default |
|--------|-------------|------|
| `--model` | LLM model name | `llama3.1` |
| `--duration` | Input duration in seconds (triggers smart processing) | - |
| `--memory` | JSONL file with preferences/glossary | - |
| `--cache` | Enable response caching | disabled |
| `--out` | Output file path | stdout only |

### Environment Variables

- `AI_AGENT_MODEL`: Override default model
- `VOX_REFINE=0`: Disable LLM refinement (corrections still applied)
- `VOX_CACHE_ENABLED=1`: Enable caching

## üîó Integration with macOS PTT Dictation

VoxCompose seamlessly integrates with [VoxCore](https://github.com/cliffmin/voxcore) for complete voice-to-text workflow:

1. **macOS PTT** captures audio with push-to-talk (F13/Shift+F13)
2. **Whisper** transcribes audio to text
3. **VoxCompose** applies corrections and optional LLM refinement
4. **Result**: Polished Markdown ready for use

### Setup Integration

```lua
-- In ~/.hammerspoon/ptt_config.lua
LLM_REFINER = {
  ENABLED = true,
  CMD = { "/opt/homebrew/bin/voxcompose" },
  ARGS = { "--model", "llama3.1", "--duration", "{{DURATION}}" },
}
```

## üß™ Testing

### Run Complete Test Suite

```bash
# Run all tests
./tests/run_tests.sh

# Individual tests:
./tests/validate_self_learning.sh  # Core validation
./tests/test_capabilities.sh       # Capabilities endpoint
./tests/test_duration_threshold.sh # Duration logic
./tests/generate_metrics.sh        # Performance report
```

### Expected Results

```
‚úì Self-learning: 100% correction accuracy
‚úì Performance: 139ms average processing
‚úì Threshold: 21s duration logic working
‚úì Coverage: All common errors fixed
```

## üì¶ Installation

### Homebrew (Recommended)

```bash
brew tap cliffmin/tap
brew install voxcompose ollama
```

<details>
<summary>Alternative: Build from source</summary>

```bash
brew install openjdk@21 ollama
git clone https://github.com/cliffmin/voxcompose.git
cd voxcompose && ./gradlew --no-daemon clean fatJar
# JAR at build/libs/voxcompose-*-all.jar
```
</details>


## Changelog

See [CHANGELOG.md](./CHANGELOG.md)
